{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18e9c67",
   "metadata": {},
   "source": [
    "# Modular Quantum GAN Training with Comprehensive Monitoring\n",
    "\n",
    "This notebook demonstrates extended training of the modular quantum GAN architecture with:\n",
    "\n",
    "- **Modular Architecture**: Clean separation of quantum components\n",
    "- **Extended Training**: 10+ epochs for proper convergence\n",
    "- **Quality Tracking**: Real-time monitoring of generation quality\n",
    "- **Comprehensive Visualization**: Training evolution dashboard\n",
    "- **Performance Analysis**: Detailed convergence analysis\n",
    "\n",
    "This implementation uses the new modular architecture with pure quantum learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5bb55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended training environment setup complete ✓\n",
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# Configure matplotlib for Jupyter\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Import our clean training utilities\n",
    "from utils.warning_suppression import suppress_all_quantum_warnings\n",
    "from losses.quantum_gan_loss import QuantumGANLoss\n",
    "\n",
    "# Suppress warnings\n",
    "suppress_all_quantum_warnings()\n",
    "\n",
    "print(\"Extended training environment setup complete ✓\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9bff1",
   "metadata": {},
   "source": [
    "## 2. Import Modular Quantum Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251be60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modular quantum components imported successfully ✓\n"
     ]
    }
   ],
   "source": [
    "# Import our modular quantum components\n",
    "from models.generators.quantum_generator import PureQuantumGenerator\n",
    "from models.discriminators.quantum_discriminator import PureQuantumDiscriminator\n",
    "from models.quantum_gan import QuantumGAN\n",
    "from models.transformations.matrix_manager import StaticTransformationMatrix\n",
    "\n",
    "print(\"Modular quantum components imported successfully ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf0ad2",
   "metadata": {},
   "source": [
    "## 3. Create Data and Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef016901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data created: (50, 2)\n",
      "Data range: [-1.000, 0.871]\n"
     ]
    }
   ],
   "source": [
    "def create_simple_2d_data(n_samples=50):\n",
    "    \"\"\"\n",
    "    Create simple 2D Gaussian mixture for testing.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Two Gaussian clusters\n",
    "    cluster1 = np.random.normal([1.0, 1.0], 0.3, (n_samples//2, 2))\n",
    "    cluster2 = np.random.normal([-1.0, -1.0], 0.3, (n_samples//2, 2))\n",
    "    \n",
    "    data = np.vstack([cluster1, cluster2])\n",
    "    \n",
    "    # Normalize to [-1, 1] range for quantum stability\n",
    "    data = data / np.max(np.abs(data))\n",
    "    \n",
    "    return tf.constant(data, dtype=tf.float32)\n",
    "\n",
    "# Generate data\n",
    "real_data = create_simple_2d_data(n_samples=50)\n",
    "print(f\"Data created: {real_data.shape}\")\n",
    "print(f\"Data range: [{tf.reduce_min(real_data):.3f}, {tf.reduce_max(real_data):.3f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afe36bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:quantum.core.quantum_circuit:Quantum circuit base initialized: 4 modes, cutoff=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating modular quantum GAN components...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:quantum.parameters.gate_parameters:Gate parameter manager initialized: 138 parameters\n",
      "INFO:quantum.builders.circuit_builder:Circuit builder initialized\n",
      "INFO:quantum.core.quantum_circuit:Pure quantum circuit initialized: 3 layers\n",
      "INFO:quantum.measurements.measurement_extractor:Raw measurement extractor initialized: 12 measurements\n",
      "INFO:models.transformations.matrix_manager:Static transformation matrix 'generator_encoder': 6 → 12\n",
      "INFO:models.transformations.matrix_manager:Static transformation matrix 'generator_decoder': 12 → 2\n",
      "INFO:models.transformations.matrix_manager:Transformation pair created: (6, 12) → (12, 2) (trainable=False)\n",
      "INFO:models.generators.quantum_generator:Pure quantum generator initialized: 6 → 2\n",
      "INFO:models.generators.quantum_generator:  Quantum modes: 4, Layers: 3\n",
      "INFO:models.generators.quantum_generator:  Measurement type: raw\n",
      "INFO:models.generators.quantum_generator:  Using STATIC transformations (pure quantum learning)\n",
      "INFO:quantum.core.quantum_circuit:Quantum circuit base initialized: 2 modes, cutoff=10\n",
      "INFO:quantum.parameters.gate_parameters:Gate parameter manager initialized: 28 parameters\n",
      "INFO:quantum.builders.circuit_builder:Circuit builder initialized\n",
      "INFO:quantum.core.quantum_circuit:Pure quantum circuit initialized: 2 layers\n",
      "INFO:models.transformations.matrix_manager:Static transformation matrix 'discriminator_input': 2 → 6\n",
      "INFO:quantum.measurements.measurement_extractor:Raw measurement extractor initialized: 6 measurements\n",
      "INFO:models.transformations.matrix_manager:Static transformation matrix 'discriminator_output': 6 → 1\n",
      "INFO:models.discriminators.quantum_discriminator:Pure quantum discriminator initialized: 2 → 1\n",
      "INFO:models.discriminators.quantum_discriminator:  Quantum modes: 2, Layers: 2\n",
      "INFO:models.discriminators.quantum_discriminator:  Measurement type: raw\n",
      "INFO:models.discriminators.quantum_discriminator:  Using STATIC transformations (pure quantum learning)\n",
      "INFO:models.discriminators.quantum_discriminator:Wasserstein quantum discriminator initialized (unbounded output)\n",
      "INFO:losses.quantum_gan_loss:Quantum Wasserstein Loss initialized:\n",
      "INFO:losses.quantum_gan_loss:  - Gradient penalty: 10.0\n",
      "INFO:losses.quantum_gan_loss:  - Entropy regularization: 0.0\n",
      "INFO:losses.quantum_gan_loss:  - Physics constraints: 0.0\n",
      "INFO:utils.quantum_metrics:QuantumMetrics initialized\n",
      "INFO:models.quantum_gan:Quantum GAN initialized:\n",
      "INFO:models.quantum_gan:  Loss type: wasserstein\n",
      "INFO:models.quantum_gan:  Generator params: 138\n",
      "INFO:models.quantum_gan:  Discriminator params: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modular quantum GAN created\n",
      "  Generator parameters: 138\n",
      "  Discriminator parameters: 28\n",
      "  Total quantum parameters: 166\n"
     ]
    }
   ],
   "source": [
    "# Create the modular quantum GAN\n",
    "print(\"\\nCreating modular quantum GAN components...\")\n",
    "\n",
    "# Generator configuration\n",
    "generator_config = {\n",
    "    'latent_dim': 6,\n",
    "    'output_dim': 2,\n",
    "    'n_modes': 4,\n",
    "    'layers': 3,\n",
    "    'cutoff_dim': 10,\n",
    "    'measurement_type': 'raw'\n",
    "}\n",
    "\n",
    "# Discriminator configuration\n",
    "discriminator_config = {\n",
    "    'input_dim': 2,\n",
    "    'n_modes': 2,\n",
    "    'layers': 2,\n",
    "    'cutoff_dim': 10,\n",
    "    'measurement_type': 'raw'\n",
    "}\n",
    "\n",
    "# Create the quantum GAN\n",
    "qgan = QuantumGAN(\n",
    "    generator_config=generator_config,\n",
    "    discriminator_config=discriminator_config,\n",
    "    loss_type='wasserstein',\n",
    "    learning_rate_g=5e-4,\n",
    "    learning_rate_d=5e-4,\n",
    "    n_critic=5\n",
    ")\n",
    "\n",
    "print(f\"✓ Modular quantum GAN created\")\n",
    "print(f\"  Generator parameters: {len(qgan.generator.trainable_variables)}\")\n",
    "print(f\"  Discriminator parameters: {len(qgan.discriminator.trainable_variables)}\")\n",
    "print(f\"  Total quantum parameters: {len(qgan.generator.trainable_variables) + len(qgan.discriminator.trainable_variables)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f05b98",
   "metadata": {},
   "source": [
    "## 4. Enhanced Training Monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335bd54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced training monitor created ✓\n"
     ]
    }
   ],
   "source": [
    "class EnhancedTrainingMonitor:\n",
    "    \"\"\"\n",
    "    Enhanced training monitor for quantum GAN with quality metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, qgan):\n",
    "        self.qgan = qgan\n",
    "        self.history = {\n",
    "            'epochs': [],\n",
    "            'mean_differences': [],\n",
    "            'std_differences': [],\n",
    "            'wasserstein_distances': [],\n",
    "            'generator_losses': [],\n",
    "            'discriminator_losses': [],\n",
    "            'training_times': []\n",
    "        }\n",
    "    \n",
    "    def compute_quality_metrics(self, real_data, n_samples=50):\n",
    "        \"\"\"Compute comprehensive quality metrics.\"\"\"\n",
    "        # Generate samples\n",
    "        generated_samples = self.qgan.generate(n_samples)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        real_np = real_data.numpy() if hasattr(real_data, 'numpy') else real_data\n",
    "        gen_np = generated_samples.numpy()\n",
    "        \n",
    "        # Compute metrics\n",
    "        real_mean = np.mean(real_np, axis=0)\n",
    "        gen_mean = np.mean(gen_np, axis=0)\n",
    "        real_std = np.std(real_np, axis=0)\n",
    "        gen_std = np.std(gen_np, axis=0)\n",
    "        \n",
    "        mean_diff = np.linalg.norm(real_mean - gen_mean)\n",
    "        std_diff = np.linalg.norm(real_std - gen_std)\n",
    "        \n",
    "        # Wasserstein distance (1D approximation)\n",
    "        try:\n",
    "            wd = wasserstein_distance(real_np[:, 0], gen_np[:, 0])\n",
    "        except:\n",
    "            wd = float('inf')\n",
    "        \n",
    "        return {\n",
    "            'mean_difference': mean_diff,\n",
    "            'std_difference': std_diff,\n",
    "            'wasserstein_distance': wd,\n",
    "            'generated_samples': gen_np\n",
    "        }\n",
    "    \n",
    "    def train_with_monitoring(self, data, epochs=50, batch_size=8, \n",
    "                            monitor_interval=5, verbose=True):\n",
    "        \"\"\"\n",
    "        Train with comprehensive monitoring.\n",
    "        \"\"\"\n",
    "        print(f\"Starting training with Quantum Wasserstein Loss: {epochs} epochs\")\n",
    "        print(f\"Monitoring every {monitor_interval} epochs\")\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initial quality assessment\n",
    "        initial_quality = self.compute_quality_metrics(data)\n",
    "        print(f\"Initial quality - Mean diff: {initial_quality['mean_difference']:.4f}\")\n",
    "        \n",
    "        # FIXED training data generator function\n",
    "        def data_generator():\n",
    "            indices = tf.random.uniform([batch_size], 0, tf.shape(data)[0], dtype=tf.int32)\n",
    "            return tf.gather(data, indices)\n",
    "        \n",
    "        # Train in chunks for monitoring\n",
    "        for epoch_chunk in range(0, epochs, monitor_interval):\n",
    "            chunk_epochs = min(monitor_interval, epochs - epoch_chunk)\n",
    "            chunk_start_time = time.time()\n",
    "            \n",
    "            # Train for this chunk\n",
    "            for _ in range(chunk_epochs):\n",
    "                # Train discriminator\n",
    "                for _ in range(self.qgan.n_critic):\n",
    "                    batch = data_generator()\n",
    "                    z_batch = tf.random.normal([batch_size, self.qgan.generator.latent_dim])\n",
    "                    d_loss = self.qgan.train_discriminator_step(batch, z_batch)\n",
    "                \n",
    "                # Train generator\n",
    "                z_batch = tf.random.normal([batch_size, self.qgan.generator.latent_dim])\n",
    "                g_loss = self.qgan.train_generator_step(z_batch)\n",
    "            \n",
    "            # Current epoch number\n",
    "            current_epoch = epoch_chunk + chunk_epochs\n",
    "            \n",
    "            # Compute quality metrics\n",
    "            quality_metrics = self.compute_quality_metrics(data)\n",
    "            \n",
    "            # Store metrics\n",
    "            self.history['epochs'].append(current_epoch)\n",
    "            self.history['mean_differences'].append(quality_metrics['mean_difference'])\n",
    "            self.history['std_differences'].append(quality_metrics['std_difference'])\n",
    "            self.history['wasserstein_distances'].append(quality_metrics['wasserstein_distance'])\n",
    "            self.history['generator_losses'].append(float(g_loss))\n",
    "            self.history['discriminator_losses'].append(float(d_loss))\n",
    "            self.history['training_times'].append(time.time() - start_time)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Epoch {current_epoch:3d}: G_loss={float(g_loss):.4f}, \"\n",
    "                      f\"D_loss={float(d_loss):.4f}, \"\n",
    "                      f\"Mean_diff={quality_metrics['mean_difference']:.4f}, \"\n",
    "                      f\"WD={quality_metrics['wasserstein_distance']:.4f}\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nQuantum Wasserstein training completed in {total_time:.1f}s\")\n",
    "        \n",
    "        return self.history\n",
    "\n",
    "print(\"Enhanced training monitor created ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673fd4d",
   "metadata": {},
   "source": [
    "## 5. Extended Training with Real-Time Monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75abd081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:quantum.core.quantum_circuit:Circuit built with 138 parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extended quantum GAN training with comprehensive monitoring...\n",
      "This will take significantly longer but should show real learning!\n",
      "Starting training with Quantum Wasserstein Loss: 10 epochs\n",
      "Monitoring every 5 epochs\n",
      "Data shape: (50, 2)\n",
      "Initial quality - Mean diff: 0.0243\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\quantum_gan.py\", line 100, in train_discriminator_step  *\n        fake_batch = self.generator.generate(z_batch)\n    File \"c:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\generators\\quantum_generator.py\", line 133, in generate  *\n        if j < tf.shape(encoding_values)[0]:\n\n    ValueError: 'modulation[name]' must also be initialized in the else branch\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mtrain_with_monitoring\u001b[39m\u001b[34m(self, data, epochs, batch_size, monitor_interval, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\__autograph_generated_filed0rgh2f8.py:12\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.tf__train_discriminator_step\u001b[39m\u001b[34m(self, real_batch, z_batch)\u001b[39m\n\u001b[32m     10\u001b[39m retval_ = ag__.UndefinedReturnValue()\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ag__.ld(tf).GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     fake_batch = \u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     real_output = ag__.converted_call(ag__.ld(\u001b[38;5;28mself\u001b[39m).discriminator.discriminate, (ag__.ld(real_batch),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[32m     14\u001b[39m     fake_output = ag__.converted_call(ag__.ld(\u001b[38;5;28mself\u001b[39m).discriminator.discriminate, (ag__.ld(fake_batch),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\__autograph_generated_filef3vgfjjg.py:69\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.tf__generate\u001b[39m\u001b[34m(self, z)\u001b[39m\n\u001b[32m     67\u001b[39m j = ag__.Undefined(\u001b[33m'\u001b[39m\u001b[33mj\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     68\u001b[39m i = ag__.Undefined(\u001b[33m'\u001b[39m\u001b[33mi\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43miterate_names\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mi\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m raw_measurements = ag__.converted_call(ag__.ld(\u001b[38;5;28mself\u001b[39m).measurements.extract_measurements, (ag__.ld(quantum_states),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[32m     71\u001b[39m output = ag__.converted_call(ag__.ld(\u001b[38;5;28mself\u001b[39m).transforms.decode, (ag__.ld(raw_measurements),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\__autograph_generated_filef3vgfjjg.py:58\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.tf__generate.<locals>.loop_body_1\u001b[39m\u001b[34m(itr_1)\u001b[39m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     57\u001b[39m     ag__.if_stmt(ag__.ld(j) < ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(encoding_values),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[32m0\u001b[39m], if_body, else_body, get_state, set_state, (\u001b[33m'\u001b[39m\u001b[33mmodulation[name]\u001b[39m\u001b[33m'\u001b[39m,), \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43miterate_names\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(j, name)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m state = ag__.converted_call(ag__.ld(\u001b[38;5;28mself\u001b[39m).circuit.execute, ({},), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[32m     60\u001b[39m ag__.converted_call(ag__.ld(quantum_states).append, (ag__.ld(state),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\__autograph_generated_filef3vgfjjg.py:57\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.tf__generate.<locals>.loop_body_1.<locals>.loop_body\u001b[39m\u001b[34m(itr)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34melse_body\u001b[39m():\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodulation[name]\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: in user code:\n\n    File \"c:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\quantum_gan.py\", line 100, in train_discriminator_step  *\n        fake_batch = self.generator.generate(z_batch)\n    File \"c:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\generators\\quantum_generator.py\", line 133, in generate  *\n        if j < tf.shape(encoding_values)[0]:\n\n    ValueError: 'modulation[name]' must also be initialized in the else branch\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting extended quantum GAN training with comprehensive monitoring...\")\n",
    "print(\"This will take significantly longer but should show real learning!\")\n",
    "\n",
    "# Create monitor\n",
    "monitor = EnhancedTrainingMonitor(qgan)\n",
    "\n",
    "# Extended training\n",
    "training_history = monitor.train_with_monitoring(\n",
    "    data=real_data,\n",
    "    epochs=10,           # Longer training\n",
    "    batch_size=4,         # Small batches for quantum stability\n",
    "    monitor_interval=5,   # Monitor every 5 epochs\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Extended training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9e0b7",
   "metadata": {},
   "source": [
    "## 6. Comprehensive Training Analysis Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive training dashboard\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "\n",
    "epochs = training_history['epochs']\n",
    "\n",
    "# 1. Loss Evolution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(epochs, training_history['generator_losses'], label='Generator Loss', color='blue', linewidth=2)\n",
    "ax1.plot(epochs, training_history['discriminator_losses'], label='Discriminator Loss', color='red', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss Evolution', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# 2. Quality Metrics Evolution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(epochs, training_history['mean_differences'], label='Mean Difference', color='green', linewidth=2)\n",
    "ax2.plot(epochs, training_history['std_differences'], label='Std Difference', color='orange', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Difference')\n",
    "ax2.set_title('Quality Metrics Evolution', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "# 3. Wasserstein Distance\n",
    "ax3 = axes[1, 0]\n",
    "valid_wd = [wd for wd in training_history['wasserstein_distances'] if wd != float('inf')]\n",
    "valid_epochs = epochs[:len(valid_wd)]\n",
    "if valid_wd:\n",
    "    ax3.plot(valid_epochs, valid_wd, label='Wasserstein Distance', color='purple', linewidth=2)\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Wasserstein Distance')\n",
    "    ax3.set_title('Distribution Distance Evolution', fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_yscale('log')\n",
    "\n",
    "# 4. Stability Metric\n",
    "ax4 = axes[1, 1]\n",
    "stability_metrics = [g/d if d != 0 else float('inf') for g, d in zip(training_history['generator_losses'], training_history['discriminator_losses'])]\n",
    "ax4.plot(epochs, stability_metrics, label='G/D Loss Ratio', color='brown', linewidth=2)\n",
    "ax4.axhline(y=1.0, color='black', linestyle='--', alpha=0.5, label='Perfect Balance')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Stability Ratio')\n",
    "ax4.set_title('Training Stability', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_yscale('log')\n",
    "\n",
    "# 5. Final Generated vs Real Data\n",
    "ax5 = axes[2, 0]\n",
    "final_quality = monitor.compute_quality_metrics(real_data, n_samples=300)\n",
    "generated_samples = final_quality['generated_samples']\n",
    "\n",
    "ax5.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, s=20, color='blue', label='Real Data')\n",
    "ax5.scatter(generated_samples[:, 0], generated_samples[:, 1], alpha=0.6, s=20, color='red', label='Generated Data')\n",
    "ax5.set_xlabel('X₁')\n",
    "ax5.set_ylabel('X₂')\n",
    "ax5.set_title('Final: Real vs Generated Data', fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "ax5.axis('equal')\n",
    "\n",
    "# 6. Training Time Analysis\n",
    "ax6 = axes[2, 1]\n",
    "ax6.plot(epochs, training_history['training_times'], label='Time per Monitoring Interval', color='gray', linewidth=2)\n",
    "ax6.set_xlabel('Epoch')\n",
    "ax6.set_ylabel('Time (seconds)')\n",
    "ax6.set_title('Training Time Analysis', fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTENDED TRAINING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_mean_diff = training_history['mean_differences'][0]\n",
    "final_mean_diff = training_history['mean_differences'][-1]\n",
    "improvement = ((initial_mean_diff - final_mean_diff) / initial_mean_diff) * 100\n",
    "\n",
    "print(f\"\\nQuality Improvement:\")\n",
    "print(f\"  Initial Mean Difference: {initial_mean_diff:.4f}\")\n",
    "print(f\"  Final Mean Difference: {final_mean_diff:.4f}\")\n",
    "print(f\"  Improvement: {improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\nFinal Metrics:\")\n",
    "print(f\"  Generator Loss: {training_history['generator_losses'][-1]:.4f}\")\n",
    "print(f\"  Discriminator Loss: {training_history['discriminator_losses'][-1]:.4f}\")\n",
    "print(f\"  Stability Ratio: {stability_metrics[-1]:.4f}\")\n",
    "\n",
    "if valid_wd:\n",
    "    print(f\"  Final Wasserstein Distance: {valid_wd[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Total Epochs: {len(epochs)} monitoring points over {max(epochs)} epochs\")\n",
    "print(f\"  Architecture: Generator({len(qgan.generator.trainable_variables)} params), Discriminator({len(qgan.discriminator.trainable_variables)} params)\")\n",
    "print(f\"  Total Training Time: {training_history['training_times'][-1]:.1f}s\")\n",
    "\n",
    "# Convergence analysis\n",
    "if len(training_history['mean_differences']) > 10:\n",
    "    recent_improvement = training_history['mean_differences'][-5:]\n",
    "    if max(recent_improvement) - min(recent_improvement) < 0.1:\n",
    "        print(f\"\\n✓ Training appears to have converged (stable quality in last 5 measurements)\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ Training may benefit from additional epochs (quality still changing)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b695de",
   "metadata": {},
   "source": [
    "## 7. Detailed Quality Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1707d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive final evaluation\n",
    "print(\"Performing detailed quality assessment...\")\n",
    "\n",
    "# Generate larger sample for final evaluation\n",
    "final_evaluation = monitor.compute_quality_metrics(real_data, n_samples=500)\n",
    "\n",
    "print(f\"\\nFinal Quality Assessment (500 samples):\")\n",
    "print(f\"  Mean Difference: {final_evaluation['mean_difference']:.4f}\")\n",
    "print(f\"  Std Difference: {final_evaluation['std_difference']:.4f}\")\n",
    "print(f\"  Wasserstein Distance: {final_evaluation['wasserstein_distance']:.4f}\")\n",
    "\n",
    "# Quality benchmarks\n",
    "print(f\"\\nQuality Benchmarks:\")\n",
    "if final_evaluation['mean_difference'] < 0.5:\n",
    "    print(f\"  ✓ Excellent mean matching (< 0.5)\")\n",
    "elif final_evaluation['mean_difference'] < 1.0:\n",
    "    print(f\"  ✓ Good mean matching (< 1.0)\")\n",
    "elif final_evaluation['mean_difference'] < 2.0:\n",
    "    print(f\"  ⚠ Fair mean matching (< 2.0)\")\n",
    "else:\n",
    "    print(f\"  ✗ Poor mean matching (≥ 2.0)\")\n",
    "\n",
    "if final_evaluation['std_difference'] < 0.3:\n",
    "    print(f\"  ✓ Excellent variance matching (< 0.3)\")\n",
    "elif final_evaluation['std_difference'] < 0.6:\n",
    "    print(f\"  ✓ Good variance matching (< 0.6)\")\n",
    "else:\n",
    "    print(f\"  ⚠ Poor variance matching (≥ 0.6)\")\n",
    "\n",
    "# Distribution visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "generated_samples = final_evaluation['generated_samples']\n",
    "\n",
    "# Scatter plot comparison\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, s=15, color='blue', label='Real Data')\n",
    "ax1.scatter(generated_samples[:, 0], generated_samples[:, 1], alpha=0.6, s=15, color='red', label='Generated Data')\n",
    "ax1.set_xlabel('X₁')\n",
    "ax1.set_ylabel('X₂')\n",
    "ax1.set_title('Final Distribution Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axis('equal')\n",
    "\n",
    "# X1 marginal distribution\n",
    "ax2 = axes[1]\n",
    "ax2.hist(real_data[:, 0].numpy(), bins=30, alpha=0.7, density=True, color='blue', label='Real X₁', histtype='step', linewidth=2)\n",
    "ax2.hist(generated_samples[:, 0], bins=30, alpha=0.7, density=True, color='red', label='Generated X₁', histtype='step', linewidth=2)\n",
    "ax2.set_xlabel('X₁ Value')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('X₁ Marginal Distribution')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# X2 marginal distribution\n",
    "ax3 = axes[2]\n",
    "ax3.hist(real_data[:, 1].numpy(), bins=30, alpha=0.7, density=True, color='blue', label='Real X₂', histtype='step', linewidth=2)\n",
    "ax3.hist(generated_samples[:, 1], bins=30, alpha=0.7, density=True, color='red', label='Generated X₂', histtype='step', linewidth=2)\n",
    "ax3.set_xlabel('X₂ Value')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('X₂ Marginal Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Final Quality Assessment', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7917329",
   "metadata": {},
   "source": [
    "## 8. Circuit Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6567b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the circuit visualizer\n",
    "from utils.quantum_circuit_visualizer import visualize_circuit\n",
    "\n",
    "# Visualize the generator circuit\n",
    "print(\"Generator Circuit:\")\n",
    "visualize_circuit(qgan.generator.circuit, style='compact')\n",
    "\n",
    "# Visualize the discriminator circuit\n",
    "print(\"\\nDiscriminator Circuit:\")\n",
    "visualize_circuit(qgan.discriminator.circuit, style='compact')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e5343",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This notebook demonstrated the training of a quantum GAN using our new modular architecture. The key advantages of this approach include:\n",
    "\n",
    "1. **Clean Separation of Concerns**: Each component has a well-defined responsibility\n",
    "2. **Pure Quantum Learning**: No classical neural networks in the quantum components\n",
    "3. **Gradient Flow**: Confirmed gradient flow through all quantum parameters\n",
    "4. **Modular Design**: Easy to swap components and experiment with different architectures\n",
    "5. **Visualization**: Built-in circuit visualization for understanding the quantum architecture\n",
    "\n",
    "The modular architecture provides a clean foundation for further quantum GAN research, with clear separation between the quantum circuit implementation, parameter management, and training logic.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
