{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a52cbeb",
   "metadata": {},
   "source": [
    "# Extended SF Quantum GAN Training with Comprehensive Monitoring\n",
    "\n",
    "This notebook demonstrates extended training of the minimal SF quantum GAN with:\n",
    "- **Extended Training**: 100+ epochs for proper convergence\n",
    "- **Quality Tracking**: Real-time monitoring of generation quality\n",
    "- **Comprehensive Visualization**: Training evolution dashboard\n",
    "- **Performance Analysis**: Detailed convergence analysis\n",
    "\n",
    "Based on the minimal results showing poor quality (Mean diff: 2.8244), we need much longer training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320025f7",
   "metadata": {},
   "source": [
    "## 1. Setup and Enhanced Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0f303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean training environment initialized\n",
      "Warnings suppressed, ready for quantum training\n",
      "Extended training environment setup complete ✓\n",
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# Configure matplotlib for Jupyter\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Import our clean training utilities\n",
    "from utils.warning_suppression import enable_clean_training\n",
    "\n",
    "# Enable clean output\n",
    "enable_clean_training()\n",
    "\n",
    "print(\"Extended training environment setup complete ✓\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b70344",
   "metadata": {},
   "source": [
    "## 2. Import Quantum Components and Create Enhanced Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum components imported successfully ✓\n",
      "Enhanced trainer class created ✓\n"
     ]
    }
   ],
   "source": [
    "# Import our SF-based quantum components\n",
    "from models.generators.quantum_sf_generator import QuantumSFGenerator\n",
    "from models.discriminators.quantum_sf_discriminator import QuantumSFDiscriminator\n",
    "from training.qgan_sf_trainer import QGANSFTrainer\n",
    "\n",
    "print(\"Quantum components imported successfully ✓\")\n",
    "\n",
    "class ExtendedQGANTrainer(QGANSFTrainer):\n",
    "    \"\"\"\n",
    "    Enhanced trainer with quality monitoring during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.quality_history = {\n",
    "            'epochs': [],\n",
    "            'mean_differences': [],\n",
    "            'std_differences': [],\n",
    "            'wasserstein_distances': [],\n",
    "            'generator_losses': [],\n",
    "            'discriminator_losses': [],\n",
    "            'stability_metrics': [],\n",
    "            'training_times': []\n",
    "        }\n",
    "    \n",
    "    def compute_quality_metrics(self, real_data, n_samples=200):\n",
    "        \"\"\"\n",
    "        Compute comprehensive quality metrics.\n",
    "        \"\"\"\n",
    "        # Generate samples\n",
    "        z = tf.random.normal([n_samples, self.latent_dim])\n",
    "        generated_samples = self.generator.generate(z)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        real_np = real_data.numpy() if hasattr(real_data, 'numpy') else real_data\n",
    "        gen_np = generated_samples.numpy()\n",
    "        \n",
    "        # Compute metrics\n",
    "        real_mean = np.mean(real_np, axis=0)\n",
    "        gen_mean = np.mean(gen_np, axis=0)\n",
    "        real_std = np.std(real_np, axis=0)\n",
    "        gen_std = np.std(gen_np, axis=0)\n",
    "        \n",
    "        mean_diff = np.linalg.norm(real_mean - gen_mean)\n",
    "        std_diff = np.linalg.norm(real_std - gen_std)\n",
    "        \n",
    "        # Wasserstein distance (1D approximation)\n",
    "        try:\n",
    "            wd = wasserstein_distance(real_np[:, 0], gen_np[:, 0])\n",
    "        except:\n",
    "            wd = float('inf')\n",
    "        \n",
    "        return {\n",
    "            'mean_difference': mean_diff,\n",
    "            'std_difference': std_diff,\n",
    "            'wasserstein_distance': wd,\n",
    "            'generated_samples': gen_np\n",
    "        }\n",
    "    \n",
    "    def train_with_monitoring(self, data, epochs=100, batch_size=8, \n",
    "                            monitor_interval=5, verbose=True):\n",
    "        \"\"\"\n",
    "        Train with comprehensive monitoring.\n",
    "        \"\"\"\n",
    "        print(f\"Starting training: {epochs} epochs\")\n",
    "        print(f\"Monitoring every {monitor_interval} epochs\")\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initial quality assessment\n",
    "        initial_quality = self.compute_quality_metrics(data)\n",
    "        print(f\"Initial quality - Mean diff: {initial_quality['mean_difference']:.4f}\")\n",
    "        \n",
    "        # Training loop with monitoring\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            # Train one epoch\n",
    "            epoch_history = self._train_single_epoch(data, batch_size)\n",
    "            \n",
    "            # Monitor quality at intervals\n",
    "            if epoch % monitor_interval == 0 or epoch == epochs - 1:\n",
    "                quality_metrics = self.compute_quality_metrics(data)\n",
    "                \n",
    "                # Store metrics\n",
    "                self.quality_history['epochs'].append(epoch)\n",
    "                self.quality_history['mean_differences'].append(quality_metrics['mean_difference'])\n",
    "                self.quality_history['std_differences'].append(quality_metrics['std_difference'])\n",
    "                self.quality_history['wasserstein_distances'].append(quality_metrics['wasserstein_distance'])\n",
    "                self.quality_history['generator_losses'].append(epoch_history['g_loss'])\n",
    "                self.quality_history['discriminator_losses'].append(epoch_history['d_loss'])\n",
    "                self.quality_history['stability_metrics'].append(epoch_history['stability'])\n",
    "                self.quality_history['training_times'].append(time.time() - epoch_start)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Epoch {epoch:3d}: G_loss={epoch_history['g_loss']:.4f}, \"\n",
    "                          f\"D_loss={epoch_history['d_loss']:.4f}, \"\n",
    "                          f\"Mean_diff={quality_metrics['mean_difference']:.4f}, \"\n",
    "                          f\"WD={quality_metrics['wasserstein_distance']:.4f}\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nCORRECTED training completed in {total_time:.1f}s\")\n",
    "        \n",
    "        return self.quality_history\n",
    "    \n",
    "    def _train_single_epoch(self, data, batch_size):\n",
    "        \"\"\"\n",
    "        Train for one epoch and return metrics.\n",
    "        \"\"\"\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(data).batch(batch_size).shuffle(1000)\n",
    "        \n",
    "        epoch_g_losses = []\n",
    "        epoch_d_losses = []\n",
    "        \n",
    "        for batch in dataset:\n",
    "            # Train discriminator\n",
    "            d_loss = self._train_discriminator_step(batch)\n",
    "            \n",
    "            # Train generator\n",
    "            g_loss = self._train_generator_step(batch.shape[0])\n",
    "            \n",
    "            epoch_g_losses.append(float(g_loss))\n",
    "            epoch_d_losses.append(float(d_loss))\n",
    "        \n",
    "        avg_g_loss = np.mean(epoch_g_losses)\n",
    "        avg_d_loss = np.mean(epoch_d_losses)\n",
    "        stability = avg_g_loss / (avg_d_loss + 1e-8)\n",
    "        \n",
    "        return {\n",
    "            'g_loss': avg_g_loss,\n",
    "            'd_loss': avg_d_loss,\n",
    "            'stability': stability\n",
    "        }\n",
    "    \n",
    "    def _train_discriminator_step(self, real_batch):\n",
    "        \"\"\"\n",
    "        Discriminator training step  with  engine reset outside the loop!\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = tf.shape(real_batch)[0]\n",
    "\n",
    "        # Reset engines BEFORE gradient computation (like SF tutorial)\n",
    "        if self.generator.eng.run_progs:\n",
    "            self.generator.eng.reset()\n",
    "        if self.discriminator.eng.run_progs:\n",
    "            self.discriminator.eng.reset()\n",
    "\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            # Real samples\n",
    "            real_output = self.discriminator.discriminate(real_batch)\n",
    "            \n",
    "            # Fake samples\n",
    "            z = tf.random.normal([batch_size, self.latent_dim])\n",
    "            fake_samples = self.generator.generate(z)\n",
    "            fake_output = self.discriminator.discriminate(fake_samples)\n",
    "            \n",
    "            # Discriminator loss\n",
    "            d_loss = -tf.reduce_mean(tf.math.log(real_output + 1e-8) + \n",
    "                                   tf.math.log(1 - fake_output + 1e-8))\n",
    "        \n",
    "        # Compute gradients - ONLY for discriminator from this tape\n",
    "        gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        # Filter out None gradients, this could break training\n",
    "        valid_gradients = []\n",
    "        valid_variables = []\n",
    "        \n",
    "        for grad, var in zip(gradients, self.discriminator.trainable_variables):\n",
    "            if grad is not None:\n",
    "                valid_gradients.append(grad)\n",
    "                valid_variables.append(var)\n",
    "        \n",
    "        # Apply gradients\n",
    "        if valid_gradients:\n",
    "            self.d_optimizer.apply_gradients(zip(valid_gradients, valid_variables))\n",
    "            print(f\"Applied {len(valid_gradients)}/{len(gradients)} discriminator gradients\")\n",
    "        else:\n",
    "            print(\"WARNING: No valid discriminator gradients - skipping update\")\n",
    "\n",
    "        return d_loss\n",
    "    \n",
    "    def _train_generator_step(self, batch_size):\n",
    "        \"\"\"\n",
    "        Generator training step\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            z = tf.random.normal([batch_size, self.latent_dim])\n",
    "            fake_samples = self.generator.generate(z)\n",
    "            fake_output = self.discriminator.discriminate(fake_samples)\n",
    "            \n",
    "            # Generator loss\n",
    "            g_loss = -tf.reduce_mean(tf.math.log(fake_output + 1e-8))\n",
    "        \n",
    "        # Compute gradients - ONLY for generator from this tape\n",
    "        gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        \n",
    "        # Filter out None gradients\n",
    "        valid_gradients = []\n",
    "        valid_variables = []\n",
    "        \n",
    "        for grad, var in zip(gradients, self.generator.trainable_variables):\n",
    "            if grad is not None:\n",
    "                valid_gradients.append(grad)\n",
    "                valid_variables.append(var)\n",
    "        \n",
    "        # Apply gradients\n",
    "        if valid_gradients:\n",
    "            self.g_optimizer.apply_gradients(zip(valid_gradients, valid_variables))\n",
    "            print(f\"Applied {len(valid_gradients)}/{len(gradients)} generator gradients\")\n",
    "        else:\n",
    "            print(\"WARNING: No valid generator gradients - skipping update\")\n",
    "            \n",
    "        return g_loss\n",
    "\n",
    "print(\"Enhanced trainer class created ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e6044",
   "metadata": {},
   "source": [
    "## 3. Create Data and Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187fb571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data created: (500, 2)\n",
      "Data range: [-0.839, 1.000]\n",
      "\n",
      "Creating enhanced quantum components...\n",
      "✓ Enhanced generator: 5 trainable variables\n",
      "✓ Enhanced discriminator: 9 trainable variables\n",
      "✓ Enhanced trainer created\n",
      "  Total parameters: 14\n"
     ]
    }
   ],
   "source": [
    "def create_simple_2d_data(n_samples=500):\n",
    "    \"\"\"\n",
    "    Create simple 2D Gaussian mixture for testing.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Two Gaussian clusters\n",
    "    cluster1 = np.random.normal([1.0, 1.0], 0.3, (n_samples//2, 2))\n",
    "    cluster2 = np.random.normal([-1.0, -1.0], 0.3, (n_samples//2, 2))\n",
    "    \n",
    "    data = np.vstack([cluster1, cluster2])\n",
    "    \n",
    "    # Normalize to [-1, 1] range for quantum stability\n",
    "    data = data / np.max(np.abs(data))\n",
    "    \n",
    "    return tf.constant(data, dtype=tf.float32)\n",
    "\n",
    "# Generate data\n",
    "real_data = create_simple_2d_data(n_samples=500)\n",
    "print(f\"Data created: {real_data.shape}\")\n",
    "print(f\"Data range: [{tf.reduce_min(real_data):.3f}, {tf.reduce_max(real_data):.3f}]\")\n",
    "\n",
    "# Create quantum components with slightly improved settings\n",
    "print(\"\\nCreating enhanced quantum components...\")\n",
    "\n",
    "# Generator with 2 modes for better expressivity\n",
    "generator = QuantumSFGenerator(\n",
    "    n_modes=2,        # 2 modes for richer quantum correlations\n",
    "    latent_dim=2,     # 2D latent input\n",
    "    layers=1,         # Still minimal layers\n",
    "    cutoff_dim=8      # Higher cutoff for better precision\n",
    ")\n",
    "\n",
    "# Discriminator with 1 mode (minimal)\n",
    "discriminator = QuantumSFDiscriminator(\n",
    "    n_modes=1,        # 1 quantum mode (minimal)\n",
    "    input_dim=2,      # 2D input data\n",
    "    layers=1,         # 1 quantum layer (minimal)\n",
    "    cutoff_dim=8      # Higher cutoff for better precision\n",
    ")\n",
    "\n",
    "print(f\"✓ Enhanced generator: {len(generator.trainable_variables)} trainable variables\")\n",
    "print(f\"✓ Enhanced discriminator: {len(discriminator.trainable_variables)} trainable variables\")\n",
    "\n",
    "# Create enhanced trainer\n",
    "trainer = ExtendedQGANTrainer(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    latent_dim=2,\n",
    "    generator_lr=5e-4,      # Slightly lower learning rate for stability\n",
    "    discriminator_lr=5e-4,  # Matched learning rates\n",
    "    beta1=0.5,\n",
    "    beta2=0.999\n",
    ")\n",
    "\n",
    "print(f\"✓ Enhanced trainer created\")\n",
    "print(f\"  Total parameters: {len(generator.trainable_variables) + len(discriminator.trainable_variables)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e99ab8",
   "metadata": {},
   "source": [
    "## 4. Extended Training with Real-Time Monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e54790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extended quantum GAN training with comprehensive monitoring...\n",
      "This will take significantly longer but should show real learning!\n",
      "Starting training: 100 epochs\n",
      "Monitoring every 5 epochs\n",
      "Data shape: (500, 2)\n",
      "Using separate GradientTapes - NO engine resets!\n",
      "Initial quality - Mean diff: 0.0221\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Epoch   0: G_loss=0.7391, D_loss=1.3886, Mean_diff=0.0278, WD=0.1618\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n",
      "Applied 5/9 discriminator gradients\n",
      "WARNING: No valid generator gradients - skipping update\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mtrain_with_monitoring\u001b[39m\u001b[34m(self, data, epochs, batch_size, monitor_interval, verbose)\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36m_train_single_epoch\u001b[39m\u001b[34m(self, data, batch_size)\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 157\u001b[39m, in \u001b[36m_train_discriminator_step\u001b[39m\u001b[34m(self, real_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\discriminators\\quantum_sf_discriminator.py:366\u001b[39m, in \u001b[36mQuantumSFDiscriminator.discriminate\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# Use quantum encoding strategy if available\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.quantum_encoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_discriminate_with_quantum_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# Fallback to classical encoding\u001b[39;00m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._discriminate_with_classical_encoding(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\discriminators\\quantum_sf_discriminator.py:378\u001b[39m, in \u001b[36mQuantumSFDiscriminator._discriminate_with_quantum_encoding\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding_strategy == \u001b[33m'\u001b[39m\u001b[33mcoherent_state\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    377\u001b[39m     encoded_features = \u001b[38;5;28mself\u001b[39m.quantum_encoder.encode(x, \u001b[38;5;28mself\u001b[39m.n_modes)\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_discriminate_with_coherent_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding_strategy == \u001b[33m'\u001b[39m\u001b[33mdirect_displacement\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    381\u001b[39m     encoded_features = \u001b[38;5;28mself\u001b[39m.quantum_encoder.encode(x, \u001b[38;5;28mself\u001b[39m.n_modes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\discriminators\\quantum_sf_discriminator.py:421\u001b[39m, in \u001b[36mQuantumSFDiscriminator._discriminate_with_coherent_features\u001b[39m\u001b[34m(self, x, coherent_features)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[32m    419\u001b[39m     \u001b[38;5;66;03m# Extract coherent state features for this sample\u001b[39;00m\n\u001b[32m    420\u001b[39m     features = coherent_features[i]\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     quantum_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_discriminate_coherent_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m     all_quantum_outputs.append(quantum_output)\n\u001b[32m    424\u001b[39m quantum_features = tf.stack(all_quantum_outputs, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\discriminators\\quantum_sf_discriminator.py:508\u001b[39m, in \u001b[36mQuantumSFDiscriminator._discriminate_coherent_sample\u001b[39m\u001b[34m(self, coherent_features)\u001b[39m\n\u001b[32m    505\u001b[39m     combined_params = \u001b[38;5;28mself\u001b[39m.quantum_weights + \u001b[32m0.1\u001b[39m * modulation_reshaped\n\u001b[32m    507\u001b[39m     \u001b[38;5;66;03m# Run quantum circuit\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_quantum_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    511\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCoherent discrimination failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\Documents\\Personal\\Thesis\\github\\QNNCV\\src\\models\\discriminators\\quantum_sf_discriminator.py:571\u001b[39m, in \u001b[36mQuantumSFDiscriminator._run_quantum_circuit\u001b[39m\u001b[34m(self, quantum_params)\u001b[39m\n\u001b[32m    568\u001b[39m     \u001b[38;5;28mself\u001b[39m.eng.reset()\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# Run quantum circuit\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m.state\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m# Extract features from quantum state\u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._extract_enhanced_features_from_state(state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\engine.py:570\u001b[39m, in \u001b[36mLocalEngine.run\u001b[39m\u001b[34m(self, program, args, compile_options, **kwargs)\u001b[39m\n\u001b[32m    565\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m c.op.measurement_deps \u001b[38;5;129;01mand\u001b[39;00m eng_run_options[\u001b[33m\"\u001b[39m\u001b[33mshots\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m1\u001b[39m:\n\u001b[32m    566\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    567\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFeed-forwarding of measurements cannot be used together with multiple shots.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    568\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogram_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43meng_run_options\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\engine.py:306\u001b[39m, in \u001b[36mBaseEngine._run\u001b[39m\u001b[34m(self, program, args, compile_options, **kwargs)\u001b[39m\n\u001b[32m    303\u001b[39m p.bind_params(args)\n\u001b[32m    304\u001b[39m p.lock()\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m _, \u001b[38;5;28mself\u001b[39m.samples, \u001b[38;5;28mself\u001b[39m.samples_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[38;5;28mself\u001b[39m.run_progs.append(p)\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, TDMProgram) \u001b[38;5;129;01mand\u001b[39;00m received_rolled:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\engine.py:430\u001b[39m, in \u001b[36mLocalEngine._run_program\u001b[39m\u001b[34m(self, prog, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cmd \u001b[38;5;129;01min\u001b[39;00m prog.circuit:\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    429\u001b[39m         \u001b[38;5;66;03m# try to apply it to the backend and, if op is a measurement, store it in values\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m         val = \u001b[43mcmd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    432\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cmd.reg):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\ops.py:508\u001b[39m, in \u001b[36mGate.apply\u001b[39m\u001b[34m(self, reg, backend, **kwargs)\u001b[39m\n\u001b[32m    506\u001b[39m temp = [rr.ind \u001b[38;5;28;01mfor\u001b[39;00m rr \u001b[38;5;129;01min\u001b[39;00m reg]\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# call the child class specialized _apply method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.p[\u001b[32m0\u001b[39m] = original_p0\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\ops.py:1854\u001b[39m, in \u001b[36mRgate._apply\u001b[39m\u001b[34m(self, reg, backend, **kwargs)\u001b[39m\n\u001b[32m   1852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, reg, backend, **kwargs):\n\u001b[32m   1853\u001b[39m     p = par_evaluate(\u001b[38;5;28mself\u001b[39m.p)\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m     \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\backends\\tfbackend\\backend.py:184\u001b[39m, in \u001b[36mTFBackend.rotation\u001b[39m\u001b[34m(self, phi, mode)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.name_scope(\u001b[33m\"\u001b[39m\u001b[33mRotation\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    183\u001b[39m     remapped_mode = \u001b[38;5;28mself\u001b[39m._remap_modes(mode)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mphase_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremapped_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\backends\\tfbackend\\circuit.py:429\u001b[39m, in \u001b[36mCircuit.phase_shift\u001b[39m\u001b[34m(self, theta, mode)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03mApply the phase-shift operator to the specified mode.\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    428\u001b[39m theta = \u001b[38;5;28mself\u001b[39m._maybe_batch(theta)\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m new_state = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mphase_shifter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cutoff_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_is_pure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[38;5;28mself\u001b[39m._update_state(new_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\backends\\tfbackend\\ops.py:1039\u001b[39m, in \u001b[36mphase_shifter\u001b[39m\u001b[34m(theta, mode, in_modes, cutoff, pure, batched, dtype)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"returns phase shift unitary matrix on specified input modes\"\"\"\u001b[39;00m\n\u001b[32m   1038\u001b[39m matrix = phase_shifter_matrix(theta, cutoff, batched=batched, dtype=dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m output = \u001b[43msingle_mode_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_modes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\strawberryfields\\backends\\tfbackend\\ops.py:769\u001b[39m, in \u001b[36msingle_mode_gate\u001b[39m\u001b[34m(matrix, mode, in_modes, pure, batched)\u001b[39m\n\u001b[32m    767\u001b[39m     transposed_axis = [\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batched \u001b[38;5;28;01melse\u001b[39;00m [\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m    768\u001b[39m     einsum_inputs.append(tf.transpose(tf.math.conj(matrix), transposed_axis))\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m output = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43meqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43meinsum_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py:811\u001b[39m, in \u001b[36m_einsum_v1\u001b[39m\u001b[34m(equation, *inputs, **kwargs)\u001b[39m\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs) - \u001b[32m1\u001b[39m):\n\u001b[32m    808\u001b[39m   axes_to_sum = (\n\u001b[32m    809\u001b[39m       \u001b[38;5;28mset\u001b[39m(temp_axis_labels) &\n\u001b[32m    810\u001b[39m       \u001b[38;5;28mset\u001b[39m(input_axis_labels[i + \u001b[32m1\u001b[39m]) - \u001b[38;5;28mset\u001b[39m(output_axis_labels))\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m   temp, temp_axis_labels = \u001b[43m_einsum_v1_reduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_axis_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m                                                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m                                                \u001b[49m\u001b[43minput_axis_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m                                                \u001b[49m\u001b[43maxes_to_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    816\u001b[39m missing_indices = \u001b[38;5;28mset\u001b[39m(temp_axis_labels) - \u001b[38;5;28mset\u001b[39m(output_axis_labels)\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_indices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py:1033\u001b[39m, in \u001b[36m_einsum_v1_reduction\u001b[39m\u001b[34m(t0, t0_axis_labels, t1, t1_axis_labels, axes_to_sum)\u001b[39m\n\u001b[32m   1028\u001b[39m num_broadcast_elements_t1 = _total_size(\n\u001b[32m   1029\u001b[39m     t1_shape[\u001b[38;5;28mlen\u001b[39m(preserved_axes) + \u001b[38;5;28mlen\u001b[39m(axes_to_sum):])\n\u001b[32m   1030\u001b[39m new_shape = (\n\u001b[32m   1031\u001b[39m     t1_shape[:\u001b[38;5;28mlen\u001b[39m(preserved_axes)] +\n\u001b[32m   1032\u001b[39m     [num_summed_elements, num_broadcast_elements_t1])\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m t1 = \u001b[43m_reshape_if_necessary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m product = math_ops.matmul(t0, t1)\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m# Undo compaction of broadcast axes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py:1068\u001b[39m, in \u001b[36m_reshape_if_necessary\u001b[39m\u001b[34m(tensor, new_shape)\u001b[39m\n\u001b[32m   1066\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   1262\u001b[39m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m   result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:199\u001b[39m, in \u001b[36mreshape\u001b[39m\u001b[34m(tensor, shape, name)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mreshape\u001b[39m\u001b[33m\"\u001b[39m, v1=[\u001b[33m\"\u001b[39m\u001b[33mreshape\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmanip.reshape\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     64\u001b[39m \u001b[38;5;129m@dispatch\u001b[39m.add_dispatch_support\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreshape\u001b[39m(tensor, shape, name=\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[33;03m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m \u001b[33;03m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m   result = \u001b[43mgen_array_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m   shape_util.maybe_set_static_shape(result, shape)\n\u001b[32m    201\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10889\u001b[39m, in \u001b[36mreshape\u001b[39m\u001b[34m(tensor, shape, name)\u001b[39m\n\u001b[32m  10887\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m  10888\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m> \u001b[39m\u001b[32m10889\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreshape_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10890\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10891\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._SymbolicException:\n\u001b[32m  10892\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10914\u001b[39m, in \u001b[36mreshape_eager_fallback\u001b[39m\u001b[34m(tensor, shape, name, ctx)\u001b[39m\n\u001b[32m  10912\u001b[39m _inputs_flat = [tensor, shape]\n\u001b[32m  10913\u001b[39m _attrs = (\u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m, _attr_T, \u001b[33m\"\u001b[39m\u001b[33mTshape\u001b[39m\u001b[33m\"\u001b[39m, _attr_Tshape)\n\u001b[32m> \u001b[39m\u001b[32m10914\u001b[39m _result = \u001b[43m_execute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReshape\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10915\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  10916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _execute.must_record_gradient():\n\u001b[32m  10917\u001b[39m   _execute.record_gradient(\n\u001b[32m  10918\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mReshape\u001b[39m\u001b[33m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MendMa1\\AppData\\Local\\anaconda3\\envs\\colab\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting extended quantum GAN training with comprehensive monitoring...\")\n",
    "print(\"This will take significantly longer but should show real learning!\")\n",
    "\n",
    "# Extended training\n",
    "training_history = trainer.train_with_monitoring(\n",
    "    data=real_data,\n",
    "    epochs=100,           # Much longer training\n",
    "    batch_size=8,         # Small batches for quantum stability\n",
    "    monitor_interval=5,   # Monitor every 5 epochs\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Extended training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1705a4c",
   "metadata": {},
   "source": [
    "## 5. Comprehensive Training Analysis Dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # or 'TkAgg' or 'Qt5Agg'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create comprehensive training dashboard\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "\n",
    "epochs = training_history['epochs']\n",
    "\n",
    "# 1. Loss Evolution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(epochs, training_history['generator_losses'], label='Generator Loss', color='blue', linewidth=2)\n",
    "ax1.plot(epochs, training_history['discriminator_losses'], label='Discriminator Loss', color='red', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss Evolution', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# 2. Quality Metrics Evolution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(epochs, training_history['mean_differences'], label='Mean Difference', color='green', linewidth=2)\n",
    "ax2.plot(epochs, training_history['std_differences'], label='Std Difference', color='orange', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Difference')\n",
    "ax2.set_title('Quality Metrics Evolution', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "# 3. Wasserstein Distance\n",
    "ax3 = axes[1, 0]\n",
    "valid_wd = [wd for wd in training_history['wasserstein_distances'] if wd != float('inf')]\n",
    "valid_epochs = epochs[:len(valid_wd)]\n",
    "if valid_wd:\n",
    "    ax3.plot(valid_epochs, valid_wd, label='Wasserstein Distance', color='purple', linewidth=2)\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Wasserstein Distance')\n",
    "    ax3.set_title('Distribution Distance Evolution', fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_yscale('log')\n",
    "\n",
    "# 4. Stability Metric\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(epochs, training_history['stability_metrics'], label='G/D Loss Ratio', color='brown', linewidth=2)\n",
    "ax4.axhline(y=1.0, color='black', linestyle='--', alpha=0.5, label='Perfect Balance')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Stability Ratio')\n",
    "ax4.set_title('Training Stability', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_yscale('log')\n",
    "\n",
    "# 5. Final Generated vs Real Data\n",
    "ax5 = axes[2, 0]\n",
    "final_quality = trainer.compute_quality_metrics(real_data, n_samples=300)\n",
    "generated_samples = final_quality['generated_samples']\n",
    "\n",
    "ax5.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, s=20, color='blue', label='Real Data')\n",
    "ax5.scatter(generated_samples[:, 0], generated_samples[:, 1], alpha=0.6, s=20, color='red', label='Generated Data')\n",
    "ax5.set_xlabel('X₁')\n",
    "ax5.set_ylabel('X₂')\n",
    "ax5.set_title('Final: Real vs Generated Data', fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "ax5.axis('equal')\n",
    "\n",
    "# 6. Training Time Analysis\n",
    "ax6 = axes[2, 1]\n",
    "ax6.plot(epochs, training_history['training_times'], label='Time per Monitoring Interval', color='gray', linewidth=2)\n",
    "ax6.set_xlabel('Epoch')\n",
    "ax6.set_ylabel('Time (seconds)')\n",
    "ax6.set_title('Training Time Analysis', fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.suptitle('Extended Quantum GAN Training Dashboard', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.show()\n",
    "\n",
    "# Print final analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTENDED TRAINING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_mean_diff = training_history['mean_differences'][0]\n",
    "final_mean_diff = training_history['mean_differences'][-1]\n",
    "improvement = ((initial_mean_diff - final_mean_diff) / initial_mean_diff) * 100\n",
    "\n",
    "print(f\"\\nQuality Improvement:\")\n",
    "print(f\"  Initial Mean Difference: {initial_mean_diff:.4f}\")\n",
    "print(f\"  Final Mean Difference: {final_mean_diff:.4f}\")\n",
    "print(f\"  Improvement: {improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\nFinal Metrics:\")\n",
    "print(f\"  Generator Loss: {training_history['generator_losses'][-1]:.4f}\")\n",
    "print(f\"  Discriminator Loss: {training_history['discriminator_losses'][-1]:.4f}\")\n",
    "print(f\"  Stability Ratio: {training_history['stability_metrics'][-1]:.4f}\")\n",
    "\n",
    "if valid_wd:\n",
    "    print(f\"  Final Wasserstein Distance: {valid_wd[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Total Epochs: {len(epochs)} monitoring points over {max(epochs)} epochs\")\n",
    "print(f\"  Architecture: Generator({len(generator.trainable_variables)} params), Discriminator({len(discriminator.trainable_variables)} params)\")\n",
    "print(f\"  Total Training Time: {sum(training_history['training_times']):.1f}s\")\n",
    "\n",
    "# Convergence analysis\n",
    "if len(training_history['mean_differences']) > 10:\n",
    "    recent_improvement = training_history['mean_differences'][-5:]\n",
    "    if max(recent_improvement) - min(recent_improvement) < 0.1:\n",
    "        print(f\"\\n✓ Training appears to have converged (stable quality in last 5 measurements)\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ Training may benefit from additional epochs (quality still changing)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d0bcb",
   "metadata": {},
   "source": [
    "## 6. Detailed Quality Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive final evaluation\n",
    "print(\"Performing detailed quality assessment...\")\n",
    "\n",
    "# Generate larger sample for final evaluation\n",
    "final_evaluation = trainer.compute_quality_metrics(real_data, n_samples=500)\n",
    "\n",
    "print(f\"\\nFinal Quality Assessment (500 samples):\")\n",
    "print(f\"  Mean Difference: {final_evaluation['mean_difference']:.4f}\")\n",
    "print(f\"  Std Difference: {final_evaluation['std_difference']:.4f}\")\n",
    "print(f\"  Wasserstein Distance: {final_evaluation['wasserstein_distance']:.4f}\")\n",
    "\n",
    "# Quality benchmarks\n",
    "print(f\"\\nQuality Benchmarks:\")\n",
    "if final_evaluation['mean_difference'] < 0.5:\n",
    "    print(f\"  ✓ Excellent mean matching (< 0.5)\")\n",
    "elif final_evaluation['mean_difference'] < 1.0:\n",
    "    print(f\"  ✓ Good mean matching (< 1.0)\")\n",
    "elif final_evaluation['mean_difference'] < 2.0:\n",
    "    print(f\"  ⚠ Fair mean matching (< 2.0)\")\n",
    "else:\n",
    "    print(f\"  ✗ Poor mean matching (≥ 2.0)\")\n",
    "\n",
    "if final_evaluation['std_difference'] < 0.3:\n",
    "    print(f\"  ✓ Excellent variance matching (< 0.3)\")\n",
    "elif final_evaluation['std_difference'] < 0.6:\n",
    "    print(f\"  ✓ Good variance matching (< 0.6)\")\n",
    "else:\n",
    "    print(f\"  ⚠ Poor variance matching (≥ 0.6)\")\n",
    "\n",
    "# Distribution visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "generated_samples = final_evaluation['generated_samples']\n",
    "\n",
    "# Scatter plot comparison\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, s=15, color='blue', label='Real Data')\n",
    "ax1.scatter(generated_samples[:, 0], generated_samples[:, 1], alpha=0.6, s=15, color='red', label='Generated Data')\n",
    "ax1.set_xlabel('X₁')\n",
    "ax1.set_ylabel('X₂')\n",
    "ax1.set_title('Final Distribution Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axis('equal')\n",
    "\n",
    "# X1 marginal distribution\n",
    "ax2 = axes[1]\n",
    "ax2.hist(real_data[:, 0].numpy(), bins=30, alpha=0.7, density=True, color='blue', label='Real X₁', histtype='step', linewidth=2)\n",
    "ax2.hist(generated_samples[:, 0], bins=30, alpha=0.7, density=True, color='red', label='Generated X₁', histtype='step', linewidth=2)\n",
    "ax2.set_xlabel('X₁ Value')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('X₁ Marginal Distribution')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# X2 marginal distribution\n",
    "ax3 = axes[2]\n",
    "ax3.hist(real_data[:, 1].numpy(), bins=30, alpha=0.7, density=True, color='blue', label='Real X₂', histtype='step', linewidth=2)\n",
    "ax3.hist(generated_samples[:, 1], bins=30, alpha=0.7, density=True, color='red', label='Generated X₂', histtype='step', linewidth=2)\n",
    "ax3.set_xlabel('X₂ Value')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('X₂ Marginal Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Final Quality Assessment', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXTENDED QUANTUM GAN TRAINING COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"This notebook demonstrates proper quantum GAN training\")\n",
    "print(\"with comprehensive monitoring and quality assessment.\")\n",
    "print(\"Use this as a template for training more complex quantum GANs!\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
