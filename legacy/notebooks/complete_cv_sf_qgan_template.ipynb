{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3e0c84",
   "metadata": {},
   "source": [
    "# QNNCV: Quantum Neural Networks for Continuous Variables - Google Colab Template\n",
    "\n",
    "**Continuous Variable Quantum Generative Adversarial Networks**\n",
    "\n",
    "This notebook provides a complete template for running QNNCV experiments in Google Colab with:\n",
    "- Automatic environment setup and package installation\n",
    "- GPU acceleration (when available) (Need to be activated in Runtime)\n",
    "- Repository cloning and module imports\n",
    "- Ready-to-use training templates\n",
    "- Comprehensive visualization tools\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Start:**\n",
    "1. Run all cells in order\n",
    "2. Modify the training parameters in Section 6\n",
    "3. Execute your quantum GAN experiments\n",
    "\n",
    "**Hardware Recommendation:** Use GPU runtime for faster training\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8f50c",
   "metadata": {},
   "source": [
    "**Environment Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment detection and basic setup\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "# Check if running in Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"QNNCV ENVIRONMENT SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Colab environment detected - optimizing for cloud execution\")\n",
    "    \n",
    "    # Check GPU availability\n",
    "    gpu_info = !nvidia-smi\n",
    "    if gpu_info:\n",
    "        print(\"GPU detected - will enable acceleration\")\n",
    "    else:\n",
    "        print(\"No GPU detected - using CPU (consider switching to GPU runtime)\")\n",
    "else:\n",
    "    print(\"Local environment detected\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a8bf0",
   "metadata": {},
   "source": [
    "**Package Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e34e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package installation optimized for Colab\n",
    "print(\"Installing required packages...\")\n",
    "\n",
    "# Core quantum computing packages\n",
    "!pip install -q strawberryfields\n",
    "!pip install -q tensorflow>=2.8.0\n",
    "\n",
    "# Scientific computing packages\n",
    "!pip install -q numpy scipy matplotlib seaborn\n",
    "!pip install -q pandas scikit-learn\n",
    "\n",
    "# Visualization and progress tracking\n",
    "!pip install -q plotly tqdm ipywidgets\n",
    "\n",
    "# Additional utilities\n",
    "!pip install -q psutil  # For memory monitoring\n",
    "\n",
    "print(\"Package installation completed!\")\n",
    "\n",
    "# Verify key installations\n",
    "try:\n",
    "    import strawberryfields as sf\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(f\"✓ Strawberry Fields version: {sf.__version__}\")\n",
    "    print(f\"✓ TensorFlow version: {tf.__version__}\")\n",
    "    print(f\"✓ NumPy version: {np.__version__}\")\n",
    "    print(\"All core packages installed successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Installation error: {e} :(\")\n",
    "    print(\"Please restart runtime and try again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0de652b",
   "metadata": {},
   "source": [
    "**GPU Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "print(\"Configuring TensorFlow and GPU settings...\")\n",
    "\n",
    "# Check GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✓ GPU(s) detected: {len(gpus)}\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  GPU {i}: {gpu}\")\n",
    "    \n",
    "    # Configure GPU memory growth to avoid allocation issues\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✓ GPU memory growth configured\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration warning: {e}\")\n",
    "else:\n",
    "    print(\"⚠ No GPU detected - using CPU\")\n",
    "    print(\"For faster training, consider switching to GPU runtime:\")\n",
    "    print(\"Runtime → Change runtime type → Hardware accelerator → GPU\")\n",
    "\n",
    "# Configure TensorFlow for quantum computing\n",
    "tf.config.run_functions_eagerly(False)  # Disable eager execution for performance\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"✓ TensorFlow configured for quantum computing\")\n",
    "print(f\"✓ Random seeds set for reproducibility\")\n",
    "\n",
    "# Memory monitoring setup\n",
    "import psutil\n",
    "print(f\"✓ Available RAM: {psutil.virtual_memory().available / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e43c0",
   "metadata": {},
   "source": [
    "**Repository Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Define repository URL and name\n",
    "REPO_URL = \"https://github.com/MarcoAntonioCartia/QNNCV\"\n",
    "REPO_NAME = \"QNNCV\"\n",
    "\n",
    "print(\"Setting up QNNCV repository...\")\n",
    "\n",
    "# Check if repository already exists\n",
    "if os.path.exists(REPO_NAME):\n",
    "    print(f\"Repository {REPO_NAME} already exists - updating...\")\n",
    "    %cd {REPO_NAME}\n",
    "    !git pull\n",
    "else:\n",
    "    print(f\"Cloning repository from {REPO_URL}...\")\n",
    "    !git clone {REPO_URL}\n",
    "    %cd {REPO_NAME}\n",
    "\n",
    "# Verify repository structure\n",
    "print(\"\\nRepository structure:\")\n",
    "!ls -la\n",
    "\n",
    "# Add src directory to Python path\n",
    "repo_path = os.getcwd()\n",
    "src_path = os.path.join(repo_path, 'src')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"✓ Added {src_path} to Python path\")\n",
    "\n",
    "print(f\"✓ Working directory: {os.getcwd()}\")\n",
    "print(f\"✓ Repository setup complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff33ca",
   "metadata": {},
   "source": [
    "**Import Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core scientific computing imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import strawberryfields as sf\n",
    "from scipy.stats import wasserstein_distance\n",
    "import time\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configure matplotlib for Colab\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Configure seaborn\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Importing QNNCV modules...\")\n",
    "\n",
    "try:\n",
    "    # Import QNNCV quantum components\n",
    "    from models.generators.quantum_sf_generator import QuantumSFGenerator\n",
    "    from models.discriminators.quantum_sf_discriminator import QuantumSFDiscriminator\n",
    "    from training.qgan_sf_trainer import QGANSFTrainer\n",
    "    \n",
    "    # Import utilities\n",
    "    from utils.warning_suppression import enable_clean_training\n",
    "    \n",
    "    print(\"✓ All QNNCV modules imported successfully\")\n",
    "    \n",
    "    # Enable clean training environment\n",
    "    enable_clean_training()\n",
    "    print(\"✓ Clean training environment enabled\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e} :(\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Verify repository was cloned correctly\")\n",
    "    print(\"2. Check that src/ directory exists\")\n",
    "    print(\"3. Ensure all required files are present\")\n",
    "    \n",
    "    # Show current directory contents for debugging\n",
    "    print(\"\\nCurrent directory contents:\")\n",
    "    !ls -la\n",
    "    \n",
    "    if os.path.exists('src'):\n",
    "        print(\"\\nSrc directory contents:\")\n",
    "        !ls -la src/\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENVIRONMENT SETUP COMPLETE :)\")\n",
    "print(\"=\"*50)\n",
    "print(\"Ready for quantum GAN experiments!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d8742",
   "metadata": {},
   "source": [
    "**Functionality Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b395e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running functionality tests...\")\n",
    "\n",
    "# Test 1: Basic TensorFlow and Strawberry Fields\n",
    "print(\"\\n1. Testing TensorFlow and Strawberry Fields integration...\")\n",
    "try:\n",
    "    # Create simple SF program\n",
    "    prog = sf.Program(1)\n",
    "    eng = sf.Engine(\"tf\", backend_options={\"cutoff_dim\": 5})\n",
    "    \n",
    "    with prog.context as q:\n",
    "        sf.ops.Dgate(0.5) | q[0]\n",
    "        sf.ops.MeasureHomodyne(0) | q[0]\n",
    "    \n",
    "    result = eng.run(prog)\n",
    "    print(f\"✓ SF-TensorFlow integration working\")\n",
    "    print(f\"  Sample measurement: {result.samples[0]:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"***SF-TensorFlow test failed: {e}***\")\n",
    "\n",
    "# Test 2: Quantum components\n",
    "print(\"\\n2. Testing quantum components...\")\n",
    "try:\n",
    "    # Test generator\n",
    "    generator = QuantumSFGenerator(n_modes=2, latent_dim=2, layers=1, cutoff_dim=5)\n",
    "    z_test = tf.random.normal([2, 2])\n",
    "    samples = generator.generate(z_test)\n",
    "    print(f\"✓ Generator working - output shape: {samples.shape}\")\n",
    "    \n",
    "    # Test discriminator\n",
    "    discriminator = QuantumSFDiscriminator(n_modes=1, input_dim=2, layers=1, cutoff_dim=5)\n",
    "    x_test = tf.random.normal([2, 2])\n",
    "    probs = discriminator.discriminate(x_test)\n",
    "    print(f\"✓ Discriminator working - output shape: {probs.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"***Quantum components test failed: {e}***\")\n",
    "\n",
    "# Test 3: Gradient computation\n",
    "print(\"\\n3. Testing gradient computation...\")\n",
    "try:\n",
    "    with tf.GradientTape() as tape:\n",
    "        z = tf.random.normal([1, 2])\n",
    "        output = generator.generate(z)\n",
    "        loss = tf.reduce_mean(tf.square(output))\n",
    "    \n",
    "    gradients = tape.gradient(loss, generator.trainable_variables)\n",
    "    non_none_grads = [g for g in gradients if g is not None]\n",
    "    \n",
    "    print(f\"✓ Gradients computed: {len(non_none_grads)}/{len(gradients)} non-None\")\n",
    "    print(f\"  Loss value: {loss:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"***Gradient test failed: {e}***\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FUNCTIONALITY TESTS COMPLETE\")\n",
    "print(\"=\"*40)\n",
    "print(\"System ready for quantum GAN training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412254d",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10828c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data(n_samples=1000, data_type=\"gaussian_mixture\"):\n",
    "    \"\"\"\n",
    "    Create sample data for quantum GAN training.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples to generate\n",
    "        data_type: Type of data ('gaussian_mixture', 'spiral', 'moons')\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Training data [n_samples, 2]\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    if data_type == \"gaussian_mixture\":\n",
    "        # Two Gaussian clusters\n",
    "        cluster1 = np.random.normal([1.5, 1.5], 0.4, (n_samples//2, 2))\n",
    "        cluster2 = np.random.normal([-1.5, -1.5], 0.4, (n_samples//2, 2))\n",
    "        data = np.vstack([cluster1, cluster2])\n",
    "        \n",
    "    elif data_type == \"spiral\":\n",
    "        # Spiral pattern\n",
    "        t = np.linspace(0, 4*np.pi, n_samples)\n",
    "        r = t / (4*np.pi)\n",
    "        x = r * np.cos(t) + np.random.normal(0, 0.1, n_samples)\n",
    "        y = r * np.sin(t) + np.random.normal(0, 0.1, n_samples)\n",
    "        data = np.column_stack([x, y])\n",
    "        \n",
    "    elif data_type == \"moons\":\n",
    "        # Two moons pattern\n",
    "        from sklearn.datasets import make_moons\n",
    "        data, _ = make_moons(n_samples=n_samples, noise=0.1, random_state=42)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown data_type: {data_type}\")\n",
    "    \n",
    "    # Normalize to [-1, 1] range for quantum stability\n",
    "    data = data / np.max(np.abs(data))\n",
    "    \n",
    "    return tf.constant(data, dtype=tf.float32)\n",
    "\n",
    "# Create sample data\n",
    "print(\"Creating sample training data...\")\n",
    "\n",
    "# Choose data type: 'gaussian_mixture', 'spiral', 'moons'\n",
    "DATA_TYPE = \"gaussian_mixture\"  # MODIFY THIS\n",
    "N_SAMPLES = 1000  # MODIFY THIS\n",
    "\n",
    "training_data = create_sample_data(n_samples=N_SAMPLES, data_type=DATA_TYPE)\n",
    "\n",
    "print(f\"✓ Training data created: {training_data.shape}\")\n",
    "print(f\"  Data type: {DATA_TYPE}\")\n",
    "print(f\"  Range: [{tf.reduce_min(training_data):.3f}, {tf.reduce_max(training_data):.3f}]\")\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(training_data[:, 0], training_data[:, 1], alpha=0.6, s=20)\n",
    "plt.title(f'Training Data: {DATA_TYPE.replace(\"_\", \" \").title()}')\n",
    "plt.xlabel('X₁')\n",
    "plt.ylabel('X₂')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"Data preparation complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e80da6",
   "metadata": {},
   "source": [
    "**Model Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c791bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "print(\"Configuring quantum GAN architecture...\")\n",
    "\n",
    "# =============================================================================\n",
    "# MODIFY THESE PARAMETERS FOR EXPERIMENTS\n",
    "# =============================================================================\n",
    "\n",
    "# Generator Configuration\n",
    "GENERATOR_CONFIG = {\n",
    "    'n_modes': 2,        # Number of quantum modes (output dimension)\n",
    "    'latent_dim': 2,     # Latent noise dimension for input vector\n",
    "    'layers': 2,         # Number of quantum layers\n",
    "    'cutoff_dim': 8      # Fock space cutoff\n",
    "}\n",
    "\n",
    "# Discriminator Configuration\n",
    "DISCRIMINATOR_CONFIG = {\n",
    "    'n_modes': 1,        # Number of quantum modes\n",
    "    'input_dim': 2,      # Input data dimension (should match generator output and training data)\n",
    "    'layers': 1,         # Number of quantum layers\n",
    "    'cutoff_dim': 8      # Fock space cutoff\n",
    "}\n",
    "\n",
    "# Training Configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 100,           # Number of training epochs\n",
    "    'batch_size': 16,        # Batch size (keep small for quantum stability)\n",
    "    'generator_lr': 1e-3,    # Generator learning rate\n",
    "    'discriminator_lr': 1e-3, # Discriminator learning rate\n",
    "    'beta1': 0.5,            # Adam optimizer beta1\n",
    "    'beta2': 0.999,          # Adam optimizer beta2\n",
    "    'monitor_interval': 10   # How often to compute quality metrics\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Generator: {GENERATOR_CONFIG}\")\n",
    "print(f\"  Discriminator: {DISCRIMINATOR_CONFIG}\")\n",
    "print(f\"  Training: {TRAINING_CONFIG}\")\n",
    "\n",
    "# Create quantum components\n",
    "print(\"\\nCreating quantum components...\")\n",
    "\n",
    "generator = QuantumSFGenerator(**GENERATOR_CONFIG)\n",
    "discriminator = QuantumSFDiscriminator(**DISCRIMINATOR_CONFIG)\n",
    "\n",
    "print(f\"✓ Generator created: {len(generator.trainable_variables)} trainable variables\")\n",
    "print(f\"✓ Discriminator created: {len(discriminator.trainable_variables)} trainable variables\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = QGANSFTrainer(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    latent_dim=GENERATOR_CONFIG['latent_dim'],\n",
    "    generator_lr=TRAINING_CONFIG['generator_lr'],\n",
    "    discriminator_lr=TRAINING_CONFIG['discriminator_lr'],\n",
    "    beta1=TRAINING_CONFIG['beta1'],\n",
    "    beta2=TRAINING_CONFIG['beta2']\n",
    ")\n",
    "\n",
    "print(f\"✓ Trainer created\")\n",
    "print(f\"  Total parameters: {len(generator.trainable_variables) + len(discriminator.trainable_variables)}\")\n",
    "\n",
    "print(\"\\nModel configuration complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66144058",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c14916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with monitoring\n",
    "print(\"Starting quantum GAN training...\")\n",
    "\n",
    "# Training history storage\n",
    "training_history = {\n",
    "    'epochs': [],\n",
    "    'generator_losses': [],\n",
    "    'discriminator_losses': [],\n",
    "    'quality_metrics': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in tqdm(range(TRAINING_CONFIG['epochs']), desc=\"Training\"):\n",
    "    # Train one epoch\n",
    "    epoch_history = trainer.train(\n",
    "        data=training_data,\n",
    "        epochs=1,\n",
    "        batch_size=TRAINING_CONFIG['batch_size'],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Store metrics\n",
    "    if epoch % TRAINING_CONFIG['monitor_interval'] == 0:\n",
    "        # Compute quality metrics\n",
    "        z_test = tf.random.normal([200, GENERATOR_CONFIG['latent_dim']])\n",
    "        generated_samples = generator.generate(z_test)\n",
    "        \n",
    "        real_mean = tf.reduce_mean(training_data, axis=0)\n",
    "        gen_mean = tf.reduce_mean(generated_samples, axis=0)\n",
    "        quality_metric = tf.norm(real_mean - gen_mean)\n",
    "        \n",
    "        # Store history\n",
    "        training_history['epochs'].append(epoch)\n",
    "        training_history['generator_losses'].append(float(epoch_history['g_loss'][-1]))\n",
    "        training_history['discriminator_losses'].append(float(epoch_history['d_loss'][-1]))\n",
    "        training_history['quality_metrics'].append(float(quality_metric))\n",
    "        \n",
    "        print(f\"Epoch {epoch:3d}: G_loss={epoch_history['g_loss'][-1]:.4f}, \"\n",
    "              f\"D_loss={epoch_history['d_loss'][-1]:.4f}, \"\n",
    "              f\"Quality={quality_metric:.4f}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a107570",
   "metadata": {},
   "source": [
    "**Results Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe9375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with monitoring\n",
    "print(\"Starting quantum GAN training...\")\n",
    "\n",
    "# Training history storage\n",
    "training_history = {\n",
    "    'epochs': [],\n",
    "    'generator_losses': [],\n",
    "    'discriminator_losses': [],\n",
    "    'quality_metrics': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in tqdm(range(TRAINING_CONFIG['epochs']), desc=\"Training\"):\n",
    "    # Train one epoch\n",
    "    epoch_history = trainer.train(\n",
    "        data=training_data,\n",
    "        epochs=1,\n",
    "        batch_size=TRAINING_CONFIG['batch_size'],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Store metrics\n",
    "    if epoch % TRAINING_CONFIG['monitor_interval'] == 0:\n",
    "        # Compute quality metrics\n",
    "        z_test = tf.random.normal([200, GENERATOR_CONFIG['latent_dim']])\n",
    "        generated_samples = generator.generate(z_test)\n",
    "        \n",
    "        real_mean = tf.reduce_mean(training_data, axis=0)\n",
    "        gen_mean = tf.reduce_mean(generated_samples, axis=0)\n",
    "        quality_metric = tf.norm(real_mean - gen_mean)\n",
    "        \n",
    "        # Store history\n",
    "        training_history['epochs'].append(epoch)\n",
    "        training_history['generator_losses'].append(float(epoch_history['g_loss'][-1]))\n",
    "        training_history['discriminator_losses'].append(float(epoch_history['d_loss'][-1]))\n",
    "        training_history['quality_metrics'].append(float(quality_metric))\n",
    "        \n",
    "        print(f\"Epoch {epoch:3d}: G_loss={epoch_history['g_loss'][-1]:.4f}, \"\n",
    "              f\"D_loss={epoch_history['d_loss'][-1]:.4f}, \"\n",
    "              f\"Quality={quality_metric:.4f}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14104db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # or 'TkAgg' or 'Qt5Agg'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Comprehensive results visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "epochs = training_history['epochs']\n",
    "\n",
    "# 1. Loss Evolution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(epochs, training_history['generator_losses'], label='Generator Loss', linewidth=2)\n",
    "ax1.plot(epochs, training_history['discriminator_losses'], label='Discriminator Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss Evolution')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# 2. Quality Metrics\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(epochs, training_history['quality_metrics'], label='Mean Difference', color='green', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Quality Metric')\n",
    "ax2.set_title('Generation Quality Evolution')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Final Generated vs Real Data\n",
    "ax3 = axes[1, 0]\n",
    "z_final = tf.random.normal([500, GENERATOR_CONFIG['latent_dim']])\n",
    "final_generated = generator.generate(z_final)\n",
    "\n",
    "ax3.scatter(training_data[:, 0], training_data[:, 1], alpha=0.6, s=20, label='Real Data')\n",
    "ax3.scatter(final_generated[:, 0], final_generated[:, 1], alpha=0.6, s=20, label='Generated Data')\n",
    "ax3.set_xlabel('X₁')\n",
    "ax3.set_ylabel('X₂')\n",
    "ax3.set_title('Final: Real vs Generated Data')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.axis('equal')\n",
    "\n",
    "# 4. Training Summary\n",
    "ax4 = axes[1, 1]\n",
    "ax4.text(0.1, 0.8, f\"Training Summary:\", fontsize=14, fontweight='bold', transform=ax4.transAxes)\n",
    "ax4.text(0.1, 0.7, f\"Total Epochs: {TRAINING_CONFIG['epochs']}\", fontsize=12, transform=ax4.transAxes)\n",
    "ax4.text(0.1, 0.6, f\"Final G Loss: {training_history['generator_losses'][-1]:.4f}\", fontsize=12, transform=ax4.transAxes)\n",
    "ax4.text(0.1, 0.5, f\"Final D Loss: {training_history['discriminator_losses'][-1]:.4f}\", fontsize=12, transform=ax4.transAxes)\n",
    "ax4.text(0.1, 0.4, f\"Final Quality: {training_history['quality_metrics'][-1]:.4f}\", fontsize=12, transform=ax4.transAxes)\n",
    "ax4.text(0.1, 0.3, f\"Training Time: {total_time:.1f}s\", fontsize=12, transform=ax4.transAxes)\n",
    "ax4.set_xlim(0, 1)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Quantum GAN Training Results', fontsize=16, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"QUANTUM GAN TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Results visualization displayed above.\")\n",
    "print(\"Modify parameters and re-run for different experiments!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
